{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px; height: 163px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["# Gain Actionable Insights from Twitter Data\n\nIn this capstone project, you will use Structured Streaming to gain insight from streaming Twitter data.\n\nThe executive team would like to have access to some key business metrics such as\n* most tweeted hashtag in last 5 minute window\n* a map of where tweets are coming from\n\n## Instructions\n* Insert solutions wherever it says `FILL_IN`\n* Feel free to copy/paste code from the previous notebooks, where applicable\n* Run test cells to verify that your solution is correct\n\n## Audience\n* Primary Audience: Data Engineers\n* Additional Audiences: Data Analysts and Data Scientists\n\n## Prerequisites\n* Web browser: current versions of Google Chrome, Firefox, Safari, Microsoft Edge and \nInternet Explorer 11 on Windows 7, 8, or 10 (see <a href=\"https://docs.databricks.com/user-guide/supported-browsers.html#supported-browsers#\" target=\"_blank\">Supported Web Browsers</a>)\n* Databricks Runtime 4.2 or greater\n* Completed courses Spark-SQL, DataFrames or ETL-Part 1 from <a href=\"https://academy.databricks.com/\" target=\"_blank\">Databricks Academy</a>, or have similar knowledge\n* Have done the rest of this course"],"metadata":{}},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Getting Started</h2>\n\nRun the following cell to configure our \"classroom.\""],"metadata":{}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Step 1</h2>\n<h3>Read Streaming Data from Input Source</h3>\n\nThe input source is a a Kafka feed of Twitter data\n\nFor this step you will need to:\n0. Use the `format()` operation to specify \"kafka\" as the type of the stream\n0. Specify the location of the Kafka server by setting the option \"kafka.bootstrap.servers\" with one of the following values (depending on where you are located): \n * **server1.databricks.training:9092** (US-Oregon)\n * **server2.databricks.training:9092** (Singapore)\n0. Indicate which topics to listen to by setting the option \"subscribe\" to \"tweets\"\n0. Throttle Kafka's processing of the streams\n0. Rewind stream to beginning when we restart notebook\n0. Load the input data stream in as a DataFrame\n0. Select the column `value` - cast it to a `STRING`"],"metadata":{}},{"cell_type":"code","source":["# TODO\nfrom pyspark.sql.functions import col\nfrom pyspark.sql.types import StringType\n\nspark.conf.set(\"spark.sql.shuffle.partitions\", sc.defaultParallelism)\n\nkafkaServer = \"server1.databricks.training:9092\"   # US (Oregon)\n# kafkaServer = \"server2.databricks.training:9092\" # Singapore\n\nrawDF = (spark.readStream\n .format(\"kafka\")                     # Specify \"kafka\" as the type of the stream\n .option(\"kafka.bootstrap.servers\",kafkaServer)                 # Set the location of the kafka server\n .option(\"subscribe\",\"tweets\") # Indicate which topics to listen to\n .option(\"maxOffsetPerTrigger\",1000)# Throttle Kafka's processing of the streams\n .option(\"startingOffsets\",\"earliest\")# Rewind stream to beginning when we restart notebook\n .load() # Load the input data stream in as a DataFrame\n .select(col(\"value\").cast(StringType()))# Select the \"value\" column and cast to a string\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["# TEST - Run this cell to test your solution.\nschemaStr = str(rawDF.schema)\n\ndbTest(\"SS-06-schema-value\",     True, \"(value,StringType,true)\" in schemaStr)\ndbTest(\"SS-06-is-streaming\",     True, rawDF.isStreaming)\n\nprint(\"Tests passed!\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Tests passed!\n</div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Step 2</h2>\n<h3>A Schema for parsing JSON</h3>\n\nBecase the schema is so complex, it is being provided for you.\n\nSimply run the following cell and proceed to the next step."],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType, ArrayType\n\ntwitSchema = StructType([\n  StructField(\"hashTags\", ArrayType(StringType(), False), True),\n  StructField(\"text\", StringType(), True),   \n  StructField(\"userScreenName\", StringType(), True),\n  StructField(\"id\", LongType(), True),\n  StructField(\"createdAt\", LongType(), True),\n  StructField(\"retweetCount\", IntegerType(), True),\n  StructField(\"lang\", StringType(), True),\n  StructField(\"favoriteCount\", IntegerType(), True),\n  StructField(\"user\", StringType(), True),\n  StructField(\"place\", StructType([\n    StructField(\"coordinates\", StringType(), True), \n    StructField(\"name\", StringType(), True),\n    StructField(\"placeType\", StringType(), True),\n    StructField(\"fullName\", StringType(), True),\n    StructField(\"countryCode\", StringType(), True)]), \n  True)\n])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Step 3</h2>\n<h3>Create a JSON DataFrame</h3>\n\nFrom the `rawDF` parse out the json subfields using `from_json`. Create a DataFrame that has fields\n* `time`\n* `json`, a nested field that has all the rest of the data\n* promote all `json` subfields to fields."],"metadata":{}},{"cell_type":"code","source":["# TODO\nfrom pyspark.sql.functions import from_json, expr\n\ncleanDF = (rawDF\n .withColumn(\"json\", from_json(col(\"value\"), twitSchema))                          # Add the column \"json\" by parsing the column \"value\" with \"from_json\"\n .select(\n   expr(\"cast(cast(json.createdAt as double)/1000 as timestamp) as time\"),   # Cast \"createdAt\" column properly, call it \"time\"\n   col(\"json.hashTags\").alias(\"hashTags\"),                                     # Promote subfields of \"json\" column e.g. \"json.field\" to \"field\"\n   col(\"json.text\").alias(\"text\"),                                                                  # Repeat for each subfields of \"json\"\n   col(\"json.userScreenName\").alias(\"userScreenName\"),\n   col(\"json.id\").alias(\"id\"),\n   col(\"json.retweetCount\").alias(\"retweetCount\"),\n   col(\"json.lang\").alias(\"lang\"),\n   col(\"json.favoriteCount\").alias(\"favoriteCount\"),\n   col(\"json.user\").alias(\"user\"),\n   col(\"json.place.coordinates\").alias(\"coordinates\"),\n   col(\"json.place.name\").alias(\"name\"),\n   col(\"json.place.placeType\").alias(\"placeType\"),\n   col(\"json.place.fullName\").alias(\"fullName\"),\n   col(\"json.place.countryCode\").alias(\"countryCode\"))\n )\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["# TEST - Run this cell to test your solution.\nschemaStr = str(cleanDF.schema)\n\ndbTest(\"SS-06-schema-hashTag\",  True, \"hashTags,ArrayType(StringType,true)\" in schemaStr)\ndbTest(\"SS-06-schema-text\",  True, \"(text,StringType,true)\" in schemaStr)\ndbTest(\"SS-06-schema-userScreenName\",  True, \"(userScreenName,StringType,true)\" in schemaStr)\ndbTest(\"SS-06-schema-id\",  True, \"(id,LongType,true)\" in schemaStr)\ndbTest(\"SS-06-schema-time\",  True, \"(time,TimestampType,true)\" in schemaStr)\ndbTest(\"SS-06-schema-retweetCount\",  True, \"(retweetCount,IntegerType,true)\" in schemaStr)\ndbTest(\"SS-06-schema-lang\",  True, \"(lang,StringType,true)\" in schemaStr)\ndbTest(\"SS-06-schema-favoriteCount\",  True, \"(favoriteCount,IntegerType,true)\" in schemaStr)\ndbTest(\"SS-06-schema-user\",  True, \"(user,StringType,true)\" in schemaStr)\ndbTest(\"SS-06-schema-coordinates\",  True, \"(coordinates,StringType,true)\" in schemaStr)\ndbTest(\"SS-06-schema-name\",  True, \"(name,StringType,true)\" in schemaStr)\ndbTest(\"SS-06-schema-placeType\",  True, \"(placeType,StringType,true)\" in schemaStr)\ndbTest(\"SS-06-schema-fullName\",  True, \"(fullName,StringType,true)\" in schemaStr)\ndbTest(\"SS-06-schema-countryCode\",  True, \"(countryCode,StringType,true)\" in schemaStr)\n\nprint(\"Tests passed!\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Tests passed!\n</div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Step 4</h2>\n<h3>Display Twitter Data as a Table</h3>\n\nClick the left-most button in the bottom left corner."],"metadata":{}},{"cell_type":"code","source":["# TODO\ndisplay(cleanDF)# display \"cleanDF\""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["# TEST - Run this cell to test your solution.\ndbTest(\"SS-06-numActiveStreams\", True, len(spark.streams.active) > 0)\n       \nprint(\"Tests passed!\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Tests passed!\n</div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["When you are done, stop the stream:"],"metadata":{}},{"cell_type":"code","source":["# TODO\nfor s in spark.streams.active:\n    s.stop()                    "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"code","source":["# TEST - Run this cell to test your solution.\ndbTest(\"SS-06-numActiveStreams1\", 0, len(spark.streams.active))\n\nprint(\"Tests passed!\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Tests passed!\n</div>"]}}],"execution_count":18},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Step 5</h2>\n<h3>Hashtag Processing</h3>\n\nIn this exercise, we do ETL processing on the `hashTags` column.\n\nThe goal is to first convert hash tags all to lower case then group tweets and count by hash tags.\n\nYou will notice that `hashTags` is an array of hash tags, which you will have to break up (use `explode` function).\n\nThe `explode` method allows you to split an array column into multiple rows, copying all the other columns into each new row."],"metadata":{}},{"cell_type":"code","source":["# TODO\nfrom pyspark.sql.functions import explode, lower\n\ntwitCountsDF = (cleanDF      # Start with \"cleanDF\"\n .withColumn(\"hashTag\",explode(col(\"hashtags\")))# Explode the array \"hashTags\" into \"hashTag\"\n .withColumn(\"hashTag\", lower(col(\"hashTag\")))# Convert \"hashTag\" to lower case\n .groupby(col(\"hashTag\"))# Aggregate by \"hashTag\"...\n .count()                # For the aggregate, produce a count  \n .orderBy(col(\"count\"))  # Sort by \"count\"\n .limit(25) # Limit the result to 25 records\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":20},{"cell_type":"code","source":["# TEST - Run this cell to test your solution.\nschemaStr = str(twitCountsDF.schema)\n\ndbTest(\"SS-06-schema-hashTag\", True, \"(hashTag,StringType,true)\" in schemaStr)\ndbTest(\"SS-06-schema-count\",   True, \"(count,LongType,false)\" in schemaStr)\n\nprint(\"Tests passed!\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Tests passed!\n</div>"]}}],"execution_count":21},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Step 6</h2>\n<h3>Plot Counts of Top 25 Most Popular Hashtags</h3>\n\nUnder <b>Plot Options</b>, use the following:\n* <b>Keys:</b> `hashTag`\n* <b>Values:</b> `count`\n\nIn <b>Display type</b>, use <b>Pie Chart</b> and click <b>Apply</b>.\n\nOnce you apply the plot options, be prepared to increase the size of the plot graphic using the resize widget in the lower right corner of the graphic area."],"metadata":{}},{"cell_type":"code","source":["# TODO\ndisplay(twitCountsDF)# display twitCountsDF"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":23},{"cell_type":"code","source":["# TEST - Run this cell to test your solution.\ndbTest(\"SS-06-numActiveStreams\", True, len(spark.streams.active) > 0)\n       \nprint(\"Tests passed!\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Tests passed!\n</div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["When you are done, stop the stream:"],"metadata":{}},{"cell_type":"code","source":["for streamingQuery in spark.streams.active:\n  streamingQuery.stop()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":26},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Step 7</h2>\n<h3>Read in File with Two Letter to Three Letter Country Codes</h3>\n\nFor this next part we are going to take a look at the number of requests per country.\n\nTo get started, we first need a lookup table that will give us the 3-character country code.\n\n0. Read in the file at `/mnt/training/countries/ISOCountryCodes/ISOCountryLookup.parquet`\n0. We will be interested in the `alpha2Code` and `alpha3Code` fields later"],"metadata":{}},{"cell_type":"code","source":["# TODO\ncountryCodeDF = spark.read.parquet(\"/mnt/training/countries/ISOCountryCodes/ISOCountryLookup.parquet\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":28},{"cell_type":"code","source":["# TEST - Run this cell to test your solution.\nschemaStr = str(countryCodeDF.schema)\n\ndbTest(\"SS-06-schema-1\", True, \"(EnglishShortName,StringType,true)\" in schemaStr)\ndbTest(\"SS-06-schema-2\", True, \"(alpha2Code,StringType,true)\" in schemaStr)\ndbTest(\"SS-06-schema-3\", True, \"(alpha3Code,StringType,true)\" in schemaStr)\ndbTest(\"SS-06-schema-4\", True, \"(numericCode,StringType,true)\" in schemaStr)\ndbTest(\"SS-06-schema-5\", True, \"(ISO31662SubdivisionCode,StringType,true)\" in schemaStr)\ndbTest(\"SS-06-schema-6\", True, \"(independentTerritory,StringType,true)\" in schemaStr)\n\ndbTest(\"SS-06-streaming-7\", False, countryCodeDF.isStreaming)\n\nprint(\"Tests passed!\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Tests passed!\n</div>"]}}],"execution_count":29},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Step 8</h2>\n<h3>Join Tables &amp; Aggregate By Country</h3>\n\nIn `cleanDF`, there is a `countryCode` field. However, it is in the form of a two-letter country code.\n\nThe `display` map expects a three-letter country code.\n\nIn order to retrieve tweets with three-letter country codes, we will have to join `cleanDF` with `countryCodesDF`."],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.functions import col\nmappedDF = (cleanDF\n  .filter(col(\"countryCode\").isNotNull())                           # Filter out any nulls for \"countryCode\"\n  .join(countryCodeDF,cleanDF.countryCode==countryCodeDF.alpha2Code)  # Join the two tables on \"countryCode\" and \"alpha2Code\"\n  .groupby(col(\"EnglishShortName\"),col(\"alpha3Code\"))# Aggregate by country, \"alpha3Code\"\n  .count()                          # Produce a count of each aggregate\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":31},{"cell_type":"code","source":["# TEST - Run this cell to test your solution.\nschemaStr = str(mappedDF.schema)\nprint(schemaStr)\n\ndbTest(\"SS-06-schema-1\",  True, \"alpha3Code,StringType,true\" in schemaStr)\ndbTest(\"SS-06-schema-2\",  True, \"count,LongType,false\" in schemaStr)\n\nprint(\"Tests passed!\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">StructType(List(StructField(EnglishShortName,StringType,true),StructField(alpha3Code,StringType,true),StructField(count,LongType,false)))\nTests passed!\n</div>"]}}],"execution_count":32},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Step 9</h2>\n<h3>Plot Tweet Counts on a World Map</h3>\n\nUnder <b>Plot Options</b>, use the following:\n* <b>Keys:</b> `alpha3Code`\n* <b>Values:</b> `count`\n\nIn <b>Display type</b>, use <b>World map</b> and click <b>Apply</b>.\n\n<img src=\"https://files.training.databricks.com/images/eLearning/Structured-Streaming/plot-options-map-06.png\"/>"],"metadata":{}},{"cell_type":"code","source":["# TODO\ndisplay(mappedDF) # display mappedDF"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EnglishShortName</th><th>alpha3Code</th><th>count</th></tr></thead><tbody><tr><td>Saudi Arabia</td><td>SAU</td><td>10</td></tr><tr><td>Egypt</td><td>EGY</td><td>8</td></tr><tr><td>Jamaica</td><td>JAM</td><td>25</td></tr><tr><td>Oman</td><td>OMN</td><td>3</td></tr><tr><td>Hong Kong</td><td>HKG</td><td>4</td></tr><tr><td>Bangladesh</td><td>BGD</td><td>5</td></tr><tr><td>Switzerland</td><td>CHE</td><td>5</td></tr><tr><td>Norway</td><td>NOR</td><td>2</td></tr><tr><td>Cameroon</td><td>CMR</td><td>4</td></tr><tr><td>Serbia</td><td>SRB</td><td>2</td></tr><tr><td>Japan</td><td>JPN</td><td>8</td></tr><tr><td>China</td><td>CHN</td><td>6</td></tr><tr><td>Azerbaijan</td><td>AZE</td><td>1</td></tr><tr><td>Afghanistan</td><td>AFG</td><td>2</td></tr><tr><td>Saint Lucia</td><td>LCA</td><td>2</td></tr><tr><td>Swaziland</td><td>SWZ</td><td>1</td></tr><tr><td>Pakistan</td><td>PAK</td><td>37</td></tr><tr><td>Malawi</td><td>MWI</td><td>15</td></tr><tr><td>Spain</td><td>ESP</td><td>33</td></tr><tr><td>New Zealand</td><td>NZL</td><td>9</td></tr><tr><td>Bulgaria</td><td>BGR</td><td>1</td></tr><tr><td>Bhutan</td><td>BTN</td><td>1</td></tr><tr><td>Somalia</td><td>SOM</td><td>2</td></tr><tr><td>Korea (Republic of)</td><td>KOR</td><td>16</td></tr><tr><td>Tunisia</td><td>TUN</td><td>1</td></tr><tr><td>Nigeria</td><td>NGA</td><td>323</td></tr><tr><td>Philippines</td><td>PHL</td><td>142</td></tr><tr><td>Zambia</td><td>ZMB</td><td>14</td></tr><tr><td>Nicaragua</td><td>NIC</td><td>1</td></tr><tr><td>Guam</td><td>GUM</td><td>1</td></tr><tr><td>Bosnia and Herzegovina</td><td>BIH</td><td>1</td></tr><tr><td>Iceland</td><td>ISL</td><td>1</td></tr><tr><td>Croatia</td><td>HRV</td><td>2</td></tr><tr><td>Uganda</td><td>UGA</td><td>33</td></tr><tr><td>Israel</td><td>ISR</td><td>8</td></tr><tr><td>Botswana</td><td>BWA</td><td>17</td></tr><tr><td>Fiji</td><td>FJI</td><td>3</td></tr><tr><td>Venezuela (Bolivarian Republic of)</td><td>VEN</td><td>2</td></tr><tr><td>Canada</td><td>CAN</td><td>203</td></tr><tr><td>Portugal</td><td>PRT</td><td>11</td></tr><tr><td>Sweden</td><td>SWE</td><td>9</td></tr><tr><td>Costa Rica</td><td>CRI</td><td>1</td></tr><tr><td>Indonesia</td><td>IDN</td><td>60</td></tr><tr><td>Lithuania</td><td>LTU</td><td>2</td></tr><tr><td>Argentina</td><td>ARG</td><td>9</td></tr><tr><td>Ghana</td><td>GHA</td><td>69</td></tr><tr><td>Australia</td><td>AUS</td><td>86</td></tr><tr><td>United Arab Emirates</td><td>ARE</td><td>24</td></tr><tr><td>Iraq</td><td>IRQ</td><td>4</td></tr><tr><td>Hungary</td><td>HUN</td><td>1</td></tr><tr><td>Romania</td><td>ROU</td><td>6</td></tr><tr><td>Gibraltar</td><td>GIB</td><td>2</td></tr><tr><td>Turkey</td><td>TUR</td><td>19</td></tr><tr><td>Algeria</td><td>DZA</td><td>1</td></tr><tr><td>Lesotho</td><td>LSO</td><td>2</td></tr><tr><td>Rwanda</td><td>RWA</td><td>2</td></tr><tr><td>Bermuda</td><td>BMU</td><td>2</td></tr><tr><td>French Guiana</td><td>GUF</td><td>1</td></tr><tr><td>Bahrain</td><td>BHR</td><td>2</td></tr><tr><td>Georgia</td><td>GEO</td><td>1</td></tr><tr><td>Saint Kitts and Nevis</td><td>KNA</td><td>2</td></tr><tr><td>Netherlands</td><td>NLD</td><td>30</td></tr><tr><td>Belgium</td><td>BEL</td><td>11</td></tr><tr><td>Singapore</td><td>SGP</td><td>20</td></tr><tr><td>Zimbabwe</td><td>ZWE</td><td>9</td></tr><tr><td>Poland</td><td>POL</td><td>5</td></tr><tr><td>Cambodia</td><td>KHM</td><td>1</td></tr><tr><td>Barbados</td><td>BRB</td><td>6</td></tr><tr><td>Republic Czechia</td><td>CZE</td><td>7</td></tr><tr><td>Liberia</td><td>LBR</td><td>1</td></tr><tr><td>South Africa</td><td>ZAF</td><td>235</td></tr><tr><td>Qatar</td><td>QAT</td><td>5</td></tr><tr><td>Gambia</td><td>GMB</td><td>2</td></tr><tr><td>Mauritius</td><td>MUS</td><td>1</td></tr><tr><td>Kenya</td><td>KEN</td><td>43</td></tr><tr><td>Nepal</td><td>NPL</td><td>4</td></tr><tr><td>Bahamas</td><td>BHS</td><td>10</td></tr><tr><td>Kuwait</td><td>KWT</td><td>10</td></tr><tr><td>United Kingdom of Great Britain and Northern Ireland</td><td>GBR</td><td>1163</td></tr><tr><td>Germany</td><td>DEU</td><td>37</td></tr><tr><td>Tanzania United Republic of</td><td>TZA</td><td>10</td></tr><tr><td>Malaysia</td><td>MYS</td><td>89</td></tr><tr><td>Turks and Caicos Islands</td><td>TCA</td><td>1</td></tr><tr><td>Greece</td><td>GRC</td><td>9</td></tr><tr><td>Isle of Man</td><td>IMN</td><td>2</td></tr><tr><td>Russian Federation</td><td>RUS</td><td>7</td></tr><tr><td>Luxembourg</td><td>LUX</td><td>2</td></tr><tr><td>Austria</td><td>AUT</td><td>7</td></tr><tr><td>Namibia</td><td>NAM</td><td>15</td></tr><tr><td>Andorra</td><td>AND</td><td>1</td></tr><tr><td>Congo (Democratic Republic of the)</td><td>COD</td><td>2</td></tr><tr><td>Timor-Leste</td><td>TLS</td><td>1</td></tr><tr><td>Viet Nam</td><td>VNM</td><td>3</td></tr><tr><td>Trinidad and Tobago</td><td>TTO</td><td>9</td></tr><tr><td>Brazil</td><td>BRA</td><td>29</td></tr><tr><td>Ireland</td><td>IRL</td><td>87</td></tr><tr><td>Northern Mariana Islands</td><td>MNP</td><td>1</td></tr><tr><td>Moldova (Republic of)</td><td>MDA</td><td>1</td></tr><tr><td>Italy</td><td>ITA</td><td>30</td></tr><tr><td>Montenegro</td><td>MNE</td><td>1</td></tr><tr><td>Thailand</td><td>THA</td><td>17</td></tr><tr><td>Colombia</td><td>COL</td><td>7</td></tr><tr><td>Ukraine</td><td>UKR</td><td>7</td></tr><tr><td>Denmark</td><td>DNK</td><td>8</td></tr><tr><td>Chile</td><td>CHL</td><td>4</td></tr><tr><td>India</td><td>IND</td><td>317</td></tr><tr><td>Antigua and Barbuda</td><td>ATG</td><td>3</td></tr><tr><td>Sri Lanka</td><td>LKA</td><td>9</td></tr><tr><td>Malta</td><td>MLT</td><td>2</td></tr><tr><td>Lebanon</td><td>LBN</td><td>7</td></tr><tr><td>France</td><td>FRA</td><td>42</td></tr><tr><td>Mexico</td><td>MEX</td><td>27</td></tr><tr><td>Haiti</td><td>HTI</td><td>1</td></tr><tr><td>Cyprus</td><td>CYP</td><td>2</td></tr><tr><td>United States of America</td><td>USA</td><td>3880</td></tr><tr><td>Guernsey</td><td>GGY</td><td>1</td></tr><tr><td>Dominican Republic</td><td>DOM</td><td>1</td></tr></tbody></table></div>"]}}],"execution_count":34},{"cell_type":"code","source":["# TEST - Run this cell to test your solution.\ndbTest(\"SS-06-numActiveStreams\", True, len(spark.streams.active) > 0)\n       \nprint(\"Tests passed!\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Tests passed!\n</div>"]}}],"execution_count":35},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Step 10: Write Stream</h2>\n\nWrite the stream to an in-memory table\n0. Use appropriate `format`\n0. For this exercise, we want to append new records to the results table\n0. Gives the query a name\n0. Start the query\n0. Assign the query to `mappedTable`"],"metadata":{}},{"cell_type":"code","source":["# TODO\nmappedQuery = (mappedDF \n.writeStream                               # From the DataFrame get the DataStreamWriter\n.format(\"memory\")# Specify the sink format as \"memory\"\n.outputMode(\"complete\")                      # Configure the output mode as \"complete\"\n.queryName(\"mappedTablePython\") # Name the query \"mappedTablePython\"\n.start()                      # Start the query\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":37},{"cell_type":"code","source":["# TEST  - Run this cell to test your solution.\ndbTest(\"SS-06-isActive\", True, mappedQuery.isActive)\ndbTest(\"SS-06-name\", \"mappedTablePython\", mappedQuery.name)\n\nprint(\"Tests passed!\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Tests passed!\n</div>"]}}],"execution_count":38},{"cell_type":"markdown","source":["Wait until stream is done initializing..."],"metadata":{}},{"cell_type":"code","source":["untilStreamIsReady(\"mappedTablePython\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The stream is active and ready.\n</div>"]}}],"execution_count":40},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Step 11: Use SQL Syntax to Display a Few Rows</h2>\n\nDo a basic SQL query to display all columns and, say, 10 rows.\n\n### Why are we doing this?"],"metadata":{}},{"cell_type":"code","source":["%sql\n--TODO \nSELECT *\nFROM mappedTablePython\nLIMIT 10"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EnglishShortName</th><th>alpha3Code</th><th>count</th></tr></thead><tbody><tr><td>Saudi Arabia</td><td>SAU</td><td>10</td></tr><tr><td>Egypt</td><td>EGY</td><td>8</td></tr><tr><td>Jamaica</td><td>JAM</td><td>25</td></tr><tr><td>Oman</td><td>OMN</td><td>3</td></tr><tr><td>Hong Kong</td><td>HKG</td><td>4</td></tr><tr><td>Bangladesh</td><td>BGD</td><td>5</td></tr><tr><td>Switzerland</td><td>CHE</td><td>5</td></tr><tr><td>Norway</td><td>NOR</td><td>2</td></tr><tr><td>Cameroon</td><td>CMR</td><td>4</td></tr><tr><td>Serbia</td><td>SRB</td><td>2</td></tr></tbody></table></div>"]}}],"execution_count":42},{"cell_type":"code","source":["# TEST - Run this cell to test your solution.\ntry: tableExists = (spark.table(\"mappedTablePython\") is not None)\nexcept: tableExists = False\ndbTest(\"SS-06-1\", True, tableExists)  \n\nfirstRowCol = spark.sql(\"SELECT * FROM mappedTablePython limit 1\").first()[0]\ndbTest(\"SS-06-rowsExist\", True, len(firstRowCol) > 0) \n\nprint(\"Tests passed!\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Tests passed!\n</div>"]}}],"execution_count":43},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> Step 12: Stop Streaming Jobs</h2>\n\nBefore we can conclude, we need to shut down all active streams."],"metadata":{}},{"cell_type":"code","source":["# TODO\nfor s in spark.streams.active:  # Iterate over all the active streams\n  s.stop()# Stop the stream"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":45},{"cell_type":"code","source":["# TEST - Run this cell to test your solution.\ndbTest(\"SS-06-numActiveStreams\", 0, len(spark.streams.active))\n\nprint(\"Tests passed!\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Tests passed!\n</div>"]}}],"execution_count":46},{"cell_type":"markdown","source":["Congratulations: ALL DONE!!"],"metadata":{}},{"cell_type":"markdown","source":["Don't forget to complete this short [feedback survey](https://www.surveymonkey.com/r/YCH8FYB).  Your input is extremely important and will shape future development."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2019 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"SS 99 - Twitter Capstone","notebookId":776798901613074},"nbformat":4,"nbformat_minor":0}
